{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50828a28-facd-4978-aaa8-05babaaa1e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Część 1: Utwórz model, który klasyfikuje obrazy na dwie klasy – pochmurno, wschód słońca\n",
    "\n",
    "# Importowanie niezbędnych bibliotek\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, cohen_kappa_score\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "# Definicje funkcji pomocniczych\n",
    "\n",
    "# Funkcja do pobierania i rozpakowywania zbioru danych\n",
    "def download_and_extract_data(url, extract_to='.'):\n",
    "    local_zip = os.path.join(extract_to, 'weather.zip')\n",
    "    if not os.path.exists(local_zip):\n",
    "        response = requests.get(url, stream=True)\n",
    "        with open(local_zip, 'wb') as out_file:\n",
    "            shutil.copyfileobj(response.raw, out_file)\n",
    "        with zipfile.ZipFile(local_zip, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "    else:\n",
    "        print(\"Dataset already downloaded.\")\n",
    "\n",
    "# Pobieranie i rozpakowywanie zbioru danych\n",
    "download_and_extract_data(\"http://www.kasprowski.pl/datasets/weather.zip\")\n",
    "\n",
    "# Ścieżki do folderów z danymi treningowymi i testowymi\n",
    "base_dir = './weather'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Ustawienia ImageDataGenerator dla dwóch klas (pochmurno i wschód słońca)\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    classes=['cloudy', 'sunrise']\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    classes=['cloudy', 'sunrise']\n",
    ")\n",
    "\n",
    "# Budowanie modelu konwolucyjnej sieci neuronowej\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Kompilacja modelu\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Trenowanie modelu\n",
    "history = model.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "\n",
    "# Ocena modelu\n",
    "validation_generator.reset()\n",
    "preds = model.predict(validation_generator)\n",
    "preds = (preds > 0.5).astype(int)\n",
    "y_true = validation_generator.classes\n",
    "y_pred = preds\n",
    "\n",
    "# Wyświetlanie wyników\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "print(\"Cohen Kappa Score: \", cohen_kappa_score(y_true, y_pred))\n",
    "\n",
    "# Wizualizacja macierzy zamieszania\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Część 2: Utwórz model, który klasyfikuje obrazy na wszystkie cztery klasy\n",
    "\n",
    "# Ustawienia ImageDataGenerator dla wszystkich czterech klas\n",
    "datagen_all = ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
    "\n",
    "train_generator_all = datagen_all.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator_all = datagen_all.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Budowanie modelu konwolucyjnej sieci neuronowej dla czterech klas\n",
    "model_all = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Kompilacja modelu\n",
    "model_all.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Trenowanie modelu\n",
    "history_all = model_all.fit(train_generator_all, epochs=10, validation_data=validation_generator_all)\n",
    "\n",
    "# Ocena modelu\n",
    "validation_generator_all.reset()\n",
    "preds_all = model_all.predict(validation_generator_all)\n",
    "y_true_all = validation_generator_all.classes\n",
    "y_pred_all = np.argmax(preds_all, axis=1)\n",
    "\n",
    "# Wyświetlanie wyników\n",
    "print(\"Accuracy: \", accuracy_score(y_true_all, y_pred_all))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true_all, y_pred_all))\n",
    "print(\"Classification Report:\\n\", classification_report(y_true_all, y_pred_all))\n",
    "print(\"Cohen Kappa Score: \", cohen_kappa_score(y_true_all, y_pred_all))\n",
    "\n",
    "# Wizualizacja macierzy zamieszania\n",
    "sns.heatmap(confusion_matrix(y_true_all, y_pred_all), annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
